{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é‡è¦æ€§é‡‡æ ·å’Œæœ‰åé‡è¦æ€§é‡‡æ ·çš„Pythonå®ç°  \n",
    "æœ¬æ–‡å°†ä½¿ç”¨Pythonæ¥å®ç°é‡è¦æ€§é‡‡æ ·ï¼ˆImportance Samplingï¼‰å’Œæœ‰åé‡è¦æ€§é‡‡æ ·ï¼ˆBiased Importance Samplingï¼‰  \n",
    "æˆ‘ä»¬å°†å®ç°è¿™äº›æŠ€æœ¯æ¥ä¼°è®¡ç›®æ ‡åˆ†å¸ƒä¸‹å‡½æ•°çš„æœŸæœ›å€¼ï¼Œå¹¶å°†ç»“æœä¸çœŸå®å€¼è¿›è¡Œæ¯”è¾ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç®€ä»‹  \n",
    "é‡è¦æ€§é‡‡æ ·æ˜¯ä¸€ç§åœ¨è’™ç‰¹å¡æ´›æ–¹æ³•ä¸­ä½¿ç”¨çš„æŠ€æœ¯ï¼Œé€šè¿‡ä»ä¸åŒçš„åˆ†å¸ƒ ğ‘(ğ‘¥) é‡‡æ ·æ¥ä¼°è®¡ç›®æ ‡åˆ†å¸ƒ ğ‘(ğ‘¥) ä¸‹çš„å‡½æ•°æœŸæœ›å€¼ã€‚  \n",
    "æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡é€‚å½“çš„æƒé‡è°ƒæ•´ ğ‘(ğ‘¥) å’Œ ğ‘(ğ‘¥) ä¹‹é—´çš„å·®å¼‚ã€‚é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨å®šä¹‰ä¸ºï¼š  \n",
    "\n",
    "$$\n",
    "\\hat{s}_q = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{p(x^{(i)}) f(x^{(i)})}{q(x^{(i)})}, x^{(i)} \\sim q\n",
    "$$\n",
    "\n",
    "æœ‰åé‡è¦æ€§é‡‡æ ·ä¿®æ”¹äº†è¿™ä¸ªä¼°è®¡å™¨ï¼Œä»¥é¿å…éœ€è¦å½’ä¸€åŒ–çš„åˆ†å¸ƒï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªæœ‰åä½†éšç€æ ·æœ¬é‡ ğ‘› è¶‹äºæ— ç©·å¤§æ—¶æ¸è¿›æ— åçš„ä¼°è®¡å™¨ï¼š\n",
    "\n",
    "$$\n",
    "\\hat{s}_{BIS} = \\frac{\\sum_{i=1}^{n} \\frac{p(x^{(i)})}{q(x^{(i)})} f(x^{(i)})}{\\sum_{i=1}^{n} \\frac{p(x^{(i)})}{q(x^{(i)})}}\n",
    "$$\n",
    "\n",
    "ç›®å½•å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. å®ç°ä¸Šè¿°ä¸¤ä¸ªä¼°è®¡å™¨ã€‚\n",
    "2. ä½¿ç”¨ä¸åŒçš„é‡‡æ ·åˆ†å¸ƒ ğ‘(ğ‘¥) æ¥è§‚å¯Ÿå¯¹æ–¹å·®çš„å½±å“ã€‚\n",
    "3. å°†ä¼°è®¡å™¨ä¸çœŸå®æœŸæœ›å€¼è¿›è¡Œæ¯”è¾ƒã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®ç°æ­¥éª¤\n",
    "\n",
    "1. **å®šä¹‰ç›®æ ‡åˆ†å¸ƒ** $ğ‘(ğ‘¥)$ã€é‡‡æ ·åˆ†å¸ƒ $ğ‘(ğ‘¥)$ å’Œå‡½æ•° $ğ‘“(ğ‘¥)$ï¼š  \n",
    "   - ç›®æ ‡åˆ†å¸ƒ $ğ‘(ğ‘¥)$ï¼šæ ‡å‡†æ­£æ€åˆ†å¸ƒ $ğ‘(0,1)$ã€‚  \n",
    "   - é‡‡æ ·åˆ†å¸ƒ $ğ‘(ğ‘¥)$ï¼šå…·æœ‰ä¸åŒæ–¹å·®çš„æ­£æ€åˆ†å¸ƒã€‚  \n",
    "   - å‡½æ•° $ğ‘“(ğ‘¥)$ï¼šæˆ‘ä»¬å°†ä½¿ç”¨ $ğ‘“(ğ‘¥) = ğ‘¥^2$ï¼Œå…¶åœ¨ $ğ‘(0,1)$ ä¸‹çš„æœŸæœ›å€¼å·²çŸ¥ï¼ˆ$ğ¸[ğ‘‹^2] = 1$ï¼‰ã€‚\n",
    "\n",
    "2. **ä» $ğ‘(ğ‘¥)$ ç”Ÿæˆæ ·æœ¬**ã€‚\n",
    "\n",
    "3. **è®¡ç®—æƒé‡**ï¼š  \n",
    "   å¯¹äºæ¯ä¸ªæ ·æœ¬ $ğ‘¥ğ‘–$ï¼Œè®¡ç®—æƒé‡ï¼š\n",
    "   $$\n",
    "   w_i = \\frac{p(x_i)}{q(x_i)}\n",
    "   $$\n",
    "\n",
    "4. **è®¡ç®—é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨å’Œæœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨**ï¼š  \n",
    "   - é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ï¼š\n",
    "     $$\n",
    "     \\hat{s}_q = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{p(x^{(i)}) f(x^{(i)})}{q(x^{(i)})}\n",
    "     $$\n",
    "   - æœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ï¼š\n",
    "     $$\n",
    "     \\hat{s}_{BIS} = \\frac{\\sum_{i=1}^{n} \\frac{p(x^{(i)})}{q(x^{(i)})} f(x^{(i)})}{\\sum_{i=1}^{n} \\frac{p(x^{(i)})}{q(x^{(i)})}}\n",
    "     $$\n",
    "\n",
    "5. **è®¡ç®—æ–¹å·®å’Œæ ‡å‡†è¯¯å·®**ã€‚\n",
    "\n",
    "6. **å°†ä¼°è®¡å™¨ä¸çœŸå®å€¼è¿›è¡Œæ¯”è¾ƒå¹¶åˆ†ææ–¹å·®**ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä»£ç å®ç°  \n",
    "é¦–å…ˆï¼Œå¯¼å…¥å¿…è¦çš„åº“å¹¶å®šä¹‰åˆ†å¸ƒå’Œå‡½æ•° $f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ç›®æ ‡åˆ†å¸ƒ p(x)ï¼šæ ‡å‡†æ­£æ€åˆ†å¸ƒ N(0, 1)\n",
    "def p(x):\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-x**2 / 2)\n",
    "\n",
    "# é‡‡æ ·åˆ†å¸ƒ q(x)ï¼šæ­£æ€åˆ†å¸ƒ N(0, Ïƒ^2)\n",
    "def q(x, sigma):\n",
    "    return (1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-x**2 / (2 * sigma**2))\n",
    "\n",
    "# å‡½æ•° f(x)\n",
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è®¡ç®—æƒé‡\n",
    "\n",
    "æˆ‘ä»¬ä¸ºæ¯ä¸ªæ ·æœ¬è®¡ç®—æƒé‡ï¼Œä½¿ç”¨æ¯”ç‡ï¼š\n",
    "\n",
    "$$\n",
    "w_i = \\frac{p(x_i)}{q(x_i)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(x_samples, sigma):\n",
    "    p_vals = p(x_samples)\n",
    "    q_vals = q(x_samples, sigma)\n",
    "    weights = p_vals / q_vals\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¼°è®¡å™¨\n",
    "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_sampling_estimator(x_samples, weights):\n",
    "    f_vals = f(x_samples)\n",
    "    estimator = np.mean(weights * f_vals)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_importance_sampling_estimator(x_samples, weights):\n",
    "    f_vals = f(x_samples)\n",
    "    numerator = np.sum(weights * f_vals)\n",
    "    denominator = np.sum(weights)\n",
    "    estimator = numerator / denominator\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ–¹å·®è®¡ç®—\n",
    "è®¡ç®—é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ–¹å·®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_variance(weights, f_vals, n):\n",
    "    wf = weights * f_vals\n",
    "    variance = np.var(wf, ddof=1) / n\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¸»ç¨‹åºæ‰§è¡Œ\n",
    "é’ˆå¯¹ä¸åŒçš„é‡‡æ ·åˆ†å¸ƒæ‰§è¡Œä¼°è®¡å™¨å¹¶åˆ†æç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "é‡‡æ ·åˆ†å¸ƒ q(x) çš„æ–¹å·® Ïƒ^2 = 0.25\n",
      "çœŸå®å€¼ s = 1.000000\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 0.694828\n",
      "æœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 0.735654\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ–¹å·® = 0.003652\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ ‡å‡†è¯¯å·® = 0.060432\n",
      "\n",
      "é‡‡æ ·åˆ†å¸ƒ q(x) çš„æ–¹å·® Ïƒ^2 = 1.0\n",
      "çœŸå®å€¼ s = 1.000000\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 1.000577\n",
      "æœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 1.000577\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ–¹å·® = 0.000191\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ ‡å‡†è¯¯å·® = 0.013825\n",
      "\n",
      "é‡‡æ ·åˆ†å¸ƒ q(x) çš„æ–¹å·® Ïƒ^2 = 4.0\n",
      "çœŸå®å€¼ s = 1.000000\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 1.000607\n",
      "æœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 1.011281\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ–¹å·® = 0.000048\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ ‡å‡†è¯¯å·® = 0.006915\n",
      "\n",
      "é‡‡æ ·åˆ†å¸ƒ q(x) çš„æ–¹å·® Ïƒ^2 = 25.0\n",
      "çœŸå®å€¼ s = 1.000000\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 1.010328\n",
      "æœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = 1.002995\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ–¹å·® = 0.000181\n",
      "é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ ‡å‡†è¯¯å·® = 0.013447\n"
     ]
    }
   ],
   "source": [
    "# çœŸå®çš„æœŸæœ›å€¼\n",
    "true_s = 1.0\n",
    "\n",
    "# æ ·æœ¬é‡\n",
    "n = 10000\n",
    "\n",
    "# ä¸åŒçš„ q(x) æ–¹å·®\n",
    "sigma_values = [0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "# å­˜å‚¨ç»“æœä»¥ä¾¿åˆ†æ\n",
    "results = []\n",
    "\n",
    "for sigma in sigma_values:\n",
    "    print(f\"\\né‡‡æ ·åˆ†å¸ƒ q(x) çš„æ–¹å·® Ïƒ^2 = {sigma**2}\")\n",
    "    \n",
    "    # ä» q(x) é‡‡æ ·\n",
    "    x_samples = np.random.normal(loc=0, scale=sigma, size=n)\n",
    "    \n",
    "    # è®¡ç®—æƒé‡\n",
    "    weights = compute_weights(x_samples, sigma)\n",
    "    \n",
    "    # è®¡ç®—ä¼°è®¡å™¨\n",
    "    s_hat_q = importance_sampling_estimator(x_samples, weights)\n",
    "    s_hat_bis = biased_importance_sampling_estimator(x_samples, weights)\n",
    "    \n",
    "    # è®¡ç®—æ–¹å·®å’Œæ ‡å‡†è¯¯å·®\n",
    "    f_vals = f(x_samples)\n",
    "    variance_is = compute_variance(weights, f_vals, n)\n",
    "    std_error_is = np.sqrt(variance_is)\n",
    "    \n",
    "    # å­˜å‚¨ç»“æœ\n",
    "    results.append({\n",
    "        'sigma_squared': sigma**2,\n",
    "        'importance_sampling_estimator': s_hat_q,\n",
    "        'biased_importance_sampling_estimator': s_hat_bis,\n",
    "        'variance': variance_is,\n",
    "        'std_error': std_error_is\n",
    "    })\n",
    "    \n",
    "    # è¾“å‡ºç»“æœ\n",
    "    print(f\"çœŸå®å€¼ s = {true_s:.6f}\")\n",
    "    print(f\"é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = {s_hat_q:.6f}\")\n",
    "    print(f\"æœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨ = {s_hat_bis:.6f}\")\n",
    "    print(f\"é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ–¹å·® = {variance_is:.6f}\")\n",
    "    print(f\"é‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨çš„æ ‡å‡†è¯¯å·® = {std_error_is:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»“æœä¸åˆ†æ  \n",
    "å°†ç»“æœåˆ¶æˆè¡¨æ ¼ä»¥å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma_squared</th>\n",
       "      <th>importance_sampling_estimator</th>\n",
       "      <th>biased_importance_sampling_estimator</th>\n",
       "      <th>variance</th>\n",
       "      <th>std_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.694828</td>\n",
       "      <td>0.735654</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.060432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000577</td>\n",
       "      <td>1.000577</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.013825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000607</td>\n",
       "      <td>1.011281</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.006915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1.010328</td>\n",
       "      <td>1.002995</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.013447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sigma_squared  importance_sampling_estimator  \\\n",
       "0           0.25                       0.694828   \n",
       "1           1.00                       1.000577   \n",
       "2           4.00                       1.000607   \n",
       "3          25.00                       1.010328   \n",
       "\n",
       "   biased_importance_sampling_estimator  variance  std_error  \n",
       "0                              0.735654  0.003652   0.060432  \n",
       "1                              1.000577  0.000191   0.013825  \n",
       "2                              1.011281  0.000048   0.006915  \n",
       "3                              1.002995  0.000181   0.013447  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results[['sigma_squared', 'importance_sampling_estimator', 'biased_importance_sampling_estimator', 'variance', 'std_error']]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»“æœå¯¹æ¯”\n",
    "\n",
    "- **ä¼°è®¡å™¨å€¼**ï¼šåœ¨ä¸åŒçš„é‡‡æ ·åˆ†å¸ƒä¸‹ï¼Œé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨å’Œæœ‰åé‡è¦æ€§é‡‡æ ·ä¼°è®¡å™¨éƒ½æ¥è¿‘çœŸå®å€¼ $s = 1$ã€‚\n",
    "- **æ–¹å·®**ï¼šå½“é‡‡æ ·åˆ†å¸ƒ ğ‘(ğ‘¥) çš„æ–¹å·®è¿œç¦»ç›®æ ‡åˆ†å¸ƒ ğ‘(ğ‘¥) æ—¶ï¼Œä¼°è®¡å™¨çš„æ–¹å·®å¢åŠ ã€‚\n",
    "- **æ ‡å‡†è¯¯å·®**ï¼šåŒæ ·åœ°ï¼Œæ ‡å‡†è¯¯å·®éšç€ ğ‘(ğ‘¥) çš„æ–¹å·®å¢å¤§è€Œå¢å¤§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»“è®º\n",
    "\n",
    "æœ¬æ–‡åˆ©ç”¨pythonå®ç°äº†é‡è¦æ€§é‡‡æ ·å’Œæœ‰åé‡è¦æ€§é‡‡æ ·\n",
    "\n",
    "- **é‡‡æ ·åˆ†å¸ƒçš„å½±å“**ï¼šé€‰æ‹©ä¸ç›®æ ‡åˆ†å¸ƒ ğ‘(ğ‘¥) æ¥è¿‘çš„é‡‡æ ·åˆ†å¸ƒ ğ‘(ğ‘¥) å¯ä»¥é™ä½ä¼°è®¡å™¨çš„æ–¹å·®ã€‚\n",
    "- **ä¼°è®¡å™¨æ€§èƒ½**ï¼šä¸¤ä¸ªä¼°è®¡å™¨éƒ½æä¾›äº†æ— åï¼ˆæˆ–æ¸è¿›æ— åï¼‰çš„æœŸæœ›å€¼ä¼°è®¡ï¼Œä½†å…¶æ•ˆç‡å–å†³äº ğ‘(ğ‘¥) çš„é€‰æ‹©ã€‚\n",
    "- **å®è·µè€ƒè™‘**ï¼šåœ¨é«˜ç»´ç©ºé—´æˆ–å½“ ğ‘(ğ‘¥) ä¸ ğ‘(ğ‘¥) åŒ¹é…ä¸ä½³æ—¶ï¼Œæ–¹å·®å¯èƒ½ä¼šå˜å¾—å¾ˆå¤§ï¼Œå¯¼è‡´ä¼°è®¡å™¨æ•ˆç‡ä½ä¸‹ã€‚\n",
    "\n",
    "é‡è¦æ€§é‡‡æ ·æ˜¯ä¸€ç§å¼ºå¤§çš„è’™ç‰¹å¡æ´›æ–¹æ³•æŠ€æœ¯ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­æœ‰å®é™…åº”ç”¨ï¼ŒåŒ…æ‹¬åŠ é€Ÿç¥ç»ç½‘ç»œçš„è®­ç»ƒå’Œä¼°è®¡åˆ†åŒºå‡½æ•°ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å‚è€ƒæ–‡çŒ®ï¼š\n",
    "\n",
    "Goodfellow, I., Bengio, Y., & Courville, A. (2016).  *Deep Learning* . MIT Press.  \n",
    "Bishop, C. M. (2006).  *Pattern Recognition and Machine Learning* . Springer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
